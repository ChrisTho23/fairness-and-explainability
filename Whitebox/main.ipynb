{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing some Whitebox models\n",
    "\n",
    "We mentionned in class 5 whitebox models easily interpretable. The one we can apply for our binary classification cases are : \n",
    "1. Logistic Regression (LR)\n",
    "2. Decision Tree (DT)\n",
    "3. Generative Additive Models (GAN)\n",
    "4. Penalised Logistic Tree Regression (PLTR)\n",
    "\n",
    "**What makes a model a whitebox model :**\n",
    "- The algorithm used is straightforward to understand, and we can clearly interpret how the input features are transformed into the output or target variable.\n",
    "- We can identify the most important features to predict the target variable, and those features are understandable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "from pygam import LogisticGAM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For the model implementation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dataframe to store the results of our whitebox models\n",
    "df_whitebox_results = pd.DataFrame(columns=['Model name', 'Model parameters', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "df = pd.read_csv('Dataset/df_processed.csv')\n",
    "\n",
    "# One-hot encoding of categorical columns\n",
    "columns_to_encode = [\"Gender\", \"EthnicGroup\", \"WklyStudyHours\", \"ParentEduc\", \"LunchType\", \"ParentMaritalStatus\", \"PracticeSport\"]\n",
    "df_encoded = pd.get_dummies(df, columns=columns_to_encode)\n",
    "\n",
    "# Split the dataset\n",
    "X = df_encoded.drop('Grade', axis=1).copy()\n",
    "y = df_encoded['Grade'].copy()\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a logistic regression model\n",
    "logistic_reg = LogisticRegression()\n",
    "logistic_reg.fit(X_train, y_train)\n",
    "y_val_probabilities = logistic_reg.predict_proba(X_val)[:, 1]\n",
    "threshold = 0.5\n",
    "y_val_pred_binary = (y_val_probabilities > threshold).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics for classification\n",
    "accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "precision = precision_score(y_val, y_val_pred_binary)\n",
    "recall = recall_score(y_val, y_val_pred_binary)\n",
    "f1 = f1_score(y_val, y_val_pred_binary)\n",
    "roc_auc = roc_auc_score(y_val, y_val_probabilities)\n",
    "\n",
    "# Append the results to df_whitebox_results\n",
    "results_dict_logistic = {\n",
    "    'Model name': ['Logistic Regression'],\n",
    "    'Model parameters': [logistic_reg.get_params()],\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1],\n",
    "    'AUC-ROC': [roc_auc]\n",
    "}\n",
    "\n",
    "results_df_logistic = pd.DataFrame(results_dict_logistic)\n",
    "df_whitebox_results = pd.concat([df_whitebox_results, results_df_logistic], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the features importance\n",
    "coefficients = logistic_reg.coef_[0]\n",
    "coefficients_df = pd.DataFrame({'Features': X_train.columns, 'Coefficient': coefficients})\n",
    "coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(coefficients_df)))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(coefficients_df['Features'], coefficients_df['Coefficient'], color=colors)\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature absolute values coefficients\n",
    "coefficients = logistic_reg.coef_[0]\n",
    "coefficients_df = pd.DataFrame({'Features': X_train.columns, 'Coefficient': abs(coefficients)})\n",
    "coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(coefficients_df)))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(coefficients_df['Features'], coefficients_df['Coefficient'], color=colors)\n",
    "plt.xlabel('Absolute Coefficient')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Logistic Regression Absolute Coefficients')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whitebox_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Without hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "df = pd.read_csv('Dataset/df_processed.csv')\n",
    "\n",
    "# Convert columns into numerical categorical features\n",
    "df['Gender'] = df['Gender'].map({'female': 0, 'male': 1}) \n",
    "df['EthnicGroup'], ethnic_mapping = pd.factorize(df['EthnicGroup'])\n",
    "ethnic_group_mapping_dict = dict(enumerate(ethnic_mapping))\n",
    "df['ParentEduc'], parentEduc_mapping = pd.factorize(df['ParentEduc'])\n",
    "parentEduc_mapping_dict = dict(enumerate(parentEduc_mapping))\n",
    "df['LunchType'], lunchType_mapping = pd.factorize(df['LunchType'])\n",
    "lunchType_mapping_dict = dict(enumerate(lunchType_mapping))\n",
    "df['ParentMaritalStatus'], parentMaritalStatus_mapping = pd.factorize(df['ParentMaritalStatus'])\n",
    "parentMaritalStatus_mapping_dict = dict(enumerate(parentMaritalStatus_mapping))\n",
    "df['PracticeSport'], practiceSport_mapping = pd.factorize(df['PracticeSport'])\n",
    "practiceSport_mapping_dict = dict(enumerate(practiceSport_mapping))\n",
    "df['WklyStudyHours'], wklyStudyHours_mapping = pd.factorize(df['WklyStudyHours'])\n",
    "wklyStudyHours_mapping_dict = dict(enumerate(wklyStudyHours_mapping))\n",
    "\n",
    "# Split the dataset\n",
    "X = df.drop('Grade', axis=1).copy()\n",
    "y = df['Grade'].copy()\n",
    "\n",
    "# Create train, test, and validation data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and predict with a Decision Tree model\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_val_pred_binary = decision_tree.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics for classification\n",
    "accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "precision = precision_score(y_val, y_val_pred_binary)\n",
    "recall = recall_score(y_val, y_val_pred_binary)\n",
    "f1 = f1_score(y_val, y_val_pred_binary)\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred_binary)  # If using probabilities, you can calculate AUC-ROC\n",
    "\n",
    "# Append the results to df_whitebox_results\n",
    "results_dict_dt = {\n",
    "    'Model name': ['Decision Tree without tuning'],\n",
    "    'Model parameters': [decision_tree.get_params()],\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1],\n",
    "    'AUC-ROC': [roc_auc]\n",
    "}\n",
    "\n",
    "results_df_dt = pd.DataFrame(results_dict_dt)\n",
    "df_whitebox_results = pd.concat([df_whitebox_results, results_df_dt], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the best_decision_tree model\n",
    "feature_importances = decision_tree.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances bar plot\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(importance_df)))\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance for not tuned Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) With hyperparameter tuning \n",
    "Rq : Using Bayesian Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to minimize\n",
    "def objective(params):\n",
    "    decision_tree = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        max_leaf_nodes=params['max_leaf_nodes'],\n",
    "        min_samples_split=params['min_samples_split'],\n",
    "        min_weight_fraction_leaf=params['min_weight_fraction_leaf'],\n",
    "    )\n",
    "    score = -cross_val_score(decision_tree, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Space for hyperparameters gridsearch\n",
    "space = {\n",
    "    'max_depth': hp.randint('max_depth', 1, 13),\n",
    "    'min_samples_leaf': hp.randint('min_samples_leaf', 1, 11),\n",
    "    'max_leaf_nodes': hp.randint('max_leaf_nodes', 2, 100),\n",
    "    'min_samples_split': hp.randint('min_samples_split', 2, 21),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0.0, 0.5),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, \n",
    "            space=space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=400, \n",
    "            trials=trials, \n",
    "            rstate=np.random.default_rng(seed=42))\n",
    "\n",
    "print(\"Best Hyperparameters:\", best)\n",
    "\n",
    "best_max_depth = int(best['max_depth'])\n",
    "best_min_samples_leaf = int(best['min_samples_leaf'])\n",
    "best_max_leaf_nodes = int(best['max_leaf_nodes'])\n",
    "best_min_samples_split = int(best['min_samples_split'])\n",
    "best_min_weight_fraction_leaf = best['min_weight_fraction_leaf']\n",
    "\n",
    "# Fit the model and make predictions\n",
    "best_decision_tree = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=best_max_depth,\n",
    "    min_samples_leaf=best_min_samples_leaf,\n",
    "    max_leaf_nodes=best_max_leaf_nodes,\n",
    "    min_samples_split=best_min_samples_split,\n",
    "    min_weight_fraction_leaf=best_min_weight_fraction_leaf,\n",
    ")\n",
    "best_decision_tree.fit(X_train, y_train)\n",
    "y_val_pred_binary = best_decision_tree.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "precision = precision_score(y_val, y_val_pred_binary)\n",
    "recall = recall_score(y_val, y_val_pred_binary)\n",
    "f1 = f1_score(y_val, y_val_pred_binary)\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred_binary)\n",
    "\n",
    "# Append the results to df_whitebox_results\n",
    "results_dict_dt = {\n",
    "    'Model name': ['Decision Tree with tuning'],\n",
    "    'Model parameters': [best_decision_tree.get_params()],\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1],\n",
    "    'AUC-ROC': [roc_auc]\n",
    "}\n",
    "\n",
    "results_df_dt = pd.DataFrame(results_dict_dt)\n",
    "df_whitebox_results = pd.concat([df_whitebox_results, results_df_dt], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree logic plot  \n",
    "plt.figure(figsize=(28, 20)) \n",
    "plot_tree(\n",
    "    best_decision_tree,\n",
    "    filled=True,\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    class_names=['0', '1'],\n",
    "    fontsize=10,  \n",
    "    impurity=False  \n",
    ")\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the best_decision_tree model\n",
    "feature_importances = best_decision_tree.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances for the top 10 features\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(importance_df)))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Features Importance for tuned Decision Tree')\n",
    "plt.show()\n",
    "\n",
    "# Print top features dataframe \n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whitebox_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 - Generative additive model\n",
    "\n",
    "For the Python implementation, we can use the packages pyGAM, PiML, and statsmodels. \n",
    "\n",
    "GAN can be applied to **binary classification settings** as seen in the course (slide 39). The **additive logistic regression** will have the form : \n",
    "$$log(\\frac{\\mu(X)}{1-\\mu(X)}) = \\alpha + f_1(X_1) + â€¦ + f_p(X_p)$$\n",
    "\n",
    "The $f_i(X_i)$ denote **smooth**, **non-parametrics** functions. It could refer to any distribution from exponential family, such as Gaussian, binomial, Poisson etc...\n",
    "\n",
    "**Advantages on GAN models** : \n",
    "- It allows us to easily examine the **partial relationships** betwen the target variable and the features. Its additive nature ensures that the **marginal impact** of a single  variable **does not depend on the others** in the model.\n",
    "- The **non-linear fits** can potentially make more accurate predictions of the target. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "df = pd.read_csv('Dataset/df_processed.csv')\n",
    "\n",
    "# Convert columns into numerical categorical features\n",
    "df['Gender'] = df['Gender'].map({'female': 0, 'male': 1}) \n",
    "df['EthnicGroup'] = df['EthnicGroup'].map({'group A': 0, 'group B': 1, 'group C': 2, 'group D': 3, 'group E': 4}) \n",
    "df['ParentEduc'] = df['ParentEduc'].map({'some high school': 0, \n",
    "                                         'high school': 1, \n",
    "                                         \"associate's degree\": 2, \n",
    "                                         'some college': 3, \n",
    "                                         \"bachelor's degree\": 4,\n",
    "                                         \"master's degree\": 5}) \n",
    "df['LunchType'] = df['LunchType'].map({'standard': 0, 'free/reduced': 1}) \n",
    "df['ParentMaritalStatus'] = df['ParentMaritalStatus'].map({'widowed': 0, 'divorced': 1, 'single': 2, 'married': 3}) \n",
    "df['PracticeSport'] = df['PracticeSport'].map({'sometimes': 0, 'regularly': 1, 'never': 2}) \n",
    "df['WklyStudyHours'] = df['WklyStudyHours'].map({'Less than 5 hours': 0, 'Between 5-10 hours': 1, 'More than 10 hours': 2}) \n",
    "\n",
    "# Split the dataset\n",
    "X = df.drop('Grade', axis=1).copy()\n",
    "y = df['Grade'].copy()\n",
    "\n",
    "# Create train, test, and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration pour les sous-graphiques (3x4 pour 11 colonnes)\n",
    "nrows, ncols = 4, 3\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(15, 12))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < df.shape[1]: \n",
    "        column_values = df.iloc[:, i].value_counts()\n",
    "        ax.bar(column_values.index, column_values.values)\n",
    "        ax.set_title(df.columns[i])\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.suptitle('Bar Plots of the features', fontsize=16)\n",
    "fig.patch.set_facecolor('lightgrey')\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** the only continuous variable to which a spline function can be applied is **NrSiblings** (corresponding to the number of siblings). The other variables will be considered as intercepts whose value may vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A) Keeping all the features + With default parameters\n",
    "Rq : keeping all the features at first.\n",
    "\n",
    "- We apply a spline terms 's' for continuous numeric features (NbSiblings)\n",
    "- And factor terms 'f' for categorical features (all the others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam import LogisticGAM, s,  f\n",
    "\n",
    "n_splines = X_train.shape[1] \n",
    "X_train_array = np.array(X_train)\n",
    "y_train_array = np.array(y_train)\n",
    "# Number of siblings is the only continuous numerical variable, all others are categorical\n",
    "log_gam_1 = LogisticGAM(f(0) + f(1) + f(2) + f(3) + f(4) + f(5) + f(6) + f(7) + s(8) + f(9) + f(10),\n",
    "                      constraints = 'none').gridsearch(X_train_array, y_train_array)\n",
    "predictions = log_gam_1.predict(X_val)\n",
    "y_val_pred = predictions*1\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recall = recall_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "# Append the results to df_whitebox_results\n",
    "results_dict_GAM = {\n",
    "    'Model name': ['GAM (Keeping all features + With default parameters)'],\n",
    "    'Model parameters': [log_gam_1.get_params()],\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1],\n",
    "    'AUC-ROC': [roc_auc]\n",
    "}\n",
    "\n",
    "results_df_GAM = pd.DataFrame(results_dict_GAM)\n",
    "df_whitebox_results = pd.concat([df_whitebox_results, results_df_GAM], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot partial dependency plots\n",
    "titles = X_train.columns[0:11]\n",
    "plt.figure()\n",
    "\n",
    "fig, axs = plt.subplots(4, 3, figsize=(15, 12))  \n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < 11:  \n",
    "        XX = log_gam_1.generate_X_grid(term=i)\n",
    "        ax.plot(XX[:, i], log_gam_1.partial_dependence(term=i, X=XX))\n",
    "        ax.plot(XX[:, i], log_gam_1.partial_dependence(term=i, X=XX, width=0.8)[1], c='r', ls='--')\n",
    "        if i == 0:\n",
    "            ax.set_ylim(-30, 30)\n",
    "        ax.set_title(titles[i])\n",
    "\n",
    "plt.suptitle('Partial Dependency plots for logistic GAM model 1', fontsize=20)\n",
    "plt.subplots_adjust(top=1) \n",
    "fig.patch.set_facecolor('lightgrey')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_gam_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B) Keeping all the features + Tuning the lambda values\n",
    "\n",
    "Lambda values are : \n",
    "- by default for spline terms $s()$, the penalty value on their 2nd derivative, which encourage the functions to be smoother\n",
    "- by default for factor terms $f()$, a L2 penalty (ridge) which encourages to take on smaller weight values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = np.array(X_train)\n",
    "y_train_array = np.array(y_train)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "lams = np.random.rand(200, n_features)\n",
    "lams = lams * 6 - 3 \n",
    "lams = 10 ** lams \n",
    "\n",
    "# Number of siblings is the only continuous numerical variable, all others are categorical\n",
    "log_gam_2 = LogisticGAM(f(0) + f(1) + f(2) + f(3) + f(4) + f(5) + f(6) + f(7) + s(8) + f(9) + f(10),\n",
    "                      constraints = 'none').gridsearch(X_train_array, y_train_array, lam=lams)\n",
    "predictions = log_gam_2.predict(X_val)\n",
    "y_val_pred = predictions*1\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recall = recall_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "# Append the results to df_whitebox_results\n",
    "results_dict_GAM = {\n",
    "    'Model name': ['GAM (Keeping all features + Tuned parameters)'],\n",
    "    'Model parameters': [log_gam_2.get_params()],\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1],\n",
    "    'AUC-ROC': [roc_auc]\n",
    "}\n",
    "\n",
    "results_df_GAM = pd.DataFrame(results_dict_GAM)\n",
    "df_whitebox_results = pd.concat([df_whitebox_results, results_df_GAM], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_gam_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C) Keeping only significative features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping significant features based on p-values of the previous model\n",
    "columns_list = X_train.columns.to_list()\n",
    "columns_to_delete = [columns_list[8]]\n",
    "X_train_reduced = X_train.drop(columns=columns_to_delete).copy()\n",
    "X_val_reduced = X_val.drop(columns=columns_to_delete).copy()\n",
    "\n",
    "# Defining the model\n",
    "X_train_reduced_array = np.array(X_train_reduced)\n",
    "y_train_array = np.array(y_train)\n",
    "log_gam_3 = LogisticGAM(f(0) + f(1) + f(2) + f(3) + f(4) + f(5) + f(6) + f(7) + f(8) + f(9), \n",
    "                        constraints='none').gridsearch(X_train_reduced_array, y_train_array)\n",
    "\n",
    "# Making the predictions\n",
    "predictions = log_gam_3.predict(X_val_reduced)\n",
    "y_val_pred = predictions*1\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recall = recall_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "# Append the results to df_whitebox_results\n",
    "results_dict_GAM = {\n",
    "    'Model name': ['GAM (with significative features only + No lambda tuning)'],\n",
    "    'Model parameters': [log_gam_3.get_params()],\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1],\n",
    "    'AUC-ROC': [roc_auc]\n",
    "}\n",
    "\n",
    "results_df_GAM = pd.DataFrame(results_dict_GAM)\n",
    "df_whitebox_results = pd.concat([df_whitebox_results, results_df_GAM], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_gam_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = X_train_reduced.columns\n",
    "plt.figure()\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 12)) \n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < 7:  \n",
    "        XX = log_gam_2.generate_X_grid(term=i)\n",
    "        ax.plot(XX[:, i], log_gam_2.partial_dependence(term=i, X=XX))\n",
    "        ax.plot(XX[:, i], log_gam_2.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n",
    "        if i == 0:\n",
    "            ax.set_ylim(-30, 30)\n",
    "        ax.set_title(titles[i])\n",
    "\n",
    "plt.suptitle('Partial Dependency plots for logistic GAM model, with only significant features left', fontsize=20)\n",
    "plt.tight_layout()\n",
    "fig.patch.set_facecolor('lightgrey')\n",
    "plt.subplots_adjust(top=0.9) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D) Tuning the lambda values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping significant features based on p-values of the previous model\n",
    "columns_list = X_train.columns.to_list()\n",
    "columns_to_delete = [columns_list[8]]\n",
    "X_train_reduced = X_train.drop(columns=columns_to_delete).copy()\n",
    "X_val_reduced = X_val.drop(columns=columns_to_delete).copy()\n",
    "\n",
    "n_features = X_train_reduced.shape[1]\n",
    "lams = np.random.rand(200, n_features)\n",
    "lams = lams * 6 - 3 \n",
    "lams = 10 ** lams \n",
    "\n",
    "# Defining the model\n",
    "X_train_reduced_array = np.array(X_train_reduced)\n",
    "y_train_array = np.array(y_train)\n",
    "log_gam_4 = LogisticGAM(f(0) + f(1) + f(2) + f(3) + f(4) + f(5) + f(6) + f(7) + f(8) + f(9), \n",
    "                        constraints='none').gridsearch(X_train_reduced_array, y_train_array, lam=lams)\n",
    "\n",
    "# Making the predictions\n",
    "predictions = log_gam_4.predict(X_val_reduced)\n",
    "y_val_pred = predictions*1\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recall = recall_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "# Append the results to df_whitebox_results\n",
    "results_dict_GAM = {\n",
    "    'Model name': ['GAM (with significative features only + Lambda tuning)'],\n",
    "    'Model parameters': [log_gam_4.get_params()],\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1],\n",
    "    'AUC-ROC': [roc_auc]\n",
    "}\n",
    "\n",
    "results_df_GAM = pd.DataFrame(results_dict_GAM)\n",
    "df_whitebox_results = pd.concat([df_whitebox_results, results_df_GAM], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_gam_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = X_train_reduced.columns\n",
    "plt.figure()\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 12)) \n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < 7:  \n",
    "        XX = log_gam_4.generate_X_grid(term=i)\n",
    "        ax.plot(XX[:, i], log_gam_4.partial_dependence(term=i, X=XX))\n",
    "        ax.plot(XX[:, i], log_gam_4.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n",
    "        if i == 0:\n",
    "            ax.set_ylim(-30, 30)\n",
    "        ax.set_title(titles[i])\n",
    "\n",
    "plt.suptitle('Partial Dependency plots for logistic GAM model, with only significant features left', fontsize=20)\n",
    "plt.tight_layout()\n",
    "fig.patch.set_facecolor('lightgrey')\n",
    "plt.subplots_adjust(top=0.9)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 - Penalised Logistic Tree Regression (PLTR)\n",
    "\n",
    "PLTR uses information from **decision trees** to improve the performance of **logistic regression**. Rules extracted from various short-depth decision trees built with pairs of predictive variables are used as predictors in a penalised logistic regression model. \n",
    "\n",
    "PLTR allows us to **capture non-linear effects** that can arise in  data while preserving the intrinsic **interpretability** of the logistic regression model.\n",
    "\n",
    "**2 steps in the algorithm** : \n",
    "- 1st step : Identify threshold effects from trees with two splits. Deduce endogenous thresholds and associated predictive leafs.\n",
    "- 2nd step : Apply a **penalized** logistic regression. We try to maximise the corresponding log-likelihood, while adding a penalization term $\\lambda$ (to the negative value of the loglikelihood function more precisely) to prevent overfitting for both estimation and variable selection.\n",
    "\n",
    "Rk : $\\lambda$'s value is usually obtained with a gridsearch.\n",
    "\n",
    "In summary, PLTR is a **hybrid classification model** designed to increase the **predictive power** of the **logistic regression model** via feature engineering. It makes a good trade off between performance and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation : \n",
    "- https://towardsdatascience.com/combining-logistic-regression-and-decision-tree-1adec36a4b3f#:~:text=Summarising%2C%20combining%20logistic%20regression%20and,logistic%20regression%20are%20very%20negligible\n",
    "- https://link.springer.com/content/pdf/10.1007/s10994-005-0466-3.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 - Compare models' results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whitebox_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

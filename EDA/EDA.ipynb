{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERPRETABILITY AND ALGORITHMIC FAIRNESSES - Spotify Top Hit Playlist (2020-2021) \n",
    "The goal of this project is to apply most of the techniques presented during this course. <br>\n",
    "(The pre-commit nbstripout has been installed to delete all notebook outputs before commiting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this line creata a Kaggle token, download the resulting kaggle.json and place the file in Users/\"User\"/.kaggle/kaggle.json \n",
    "!kaggle datasets download -d desalegngeb/students-exam-scores\n",
    "!unzip students-exam-scores.zip\n",
    "os.remove(\"students-exam-scores.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Expanded_data_with_more_features.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"Original_data_with_more_rows.csv\")\n",
    "os.remove(\"Expanded_data_with_more_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis of numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle duplicates\n",
    "duplicate_rows_data = dfC[df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_rows_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each column and count the number of distinct values\n",
    "for column in dfC.columns:\n",
    "    num_distinct_values = len(dfC[column].unique())\n",
    "    print(f\"{column}: {num_distinct_values} distinct values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the Studyhours\n",
    "study_mapping = {\n",
    "    '< 5': 'Less than 5 hours',\n",
    "    '5 - 10': 'Between 5-10 hours',\n",
    "    '> 10': 'More than 10 hours'\n",
    "}\n",
    "\n",
    "# Mapping the IsFirstChild\n",
    "value_mapping = {\n",
    "    'no': 0,\n",
    "    'yes': 1\n",
    "}\n",
    "\n",
    "# Mapping the TestPrep\n",
    "test_mapping = {\n",
    "    'none': 0,\n",
    "    'completed': 1\n",
    "}\n",
    "\n",
    "# Mapping the Schoolbus\n",
    "bus_mapping = {\n",
    "    'private': 0,\n",
    "    'school_bus': 1\n",
    "}\n",
    "\n",
    "# Fixing the values in the column\n",
    "dfC['WklyStudyHours'] = dfC['WklyStudyHours'].map(study_mapping)\n",
    "dfC['IsFirstChild'] = dfC['IsFirstChild'].map(value_mapping)\n",
    "dfC['TestPrep'] = dfC['TestPrep'].map(test_mapping)\n",
    "dfC['TransportMeans'] = dfC['TransportMeans'].map(bus_mapping)\n",
    "\n",
    "# Rename the column from 'education' to 'degree'\n",
    "dfC.rename(columns={'TransportMeans': 'School_Bus'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment of missing values\n",
    "# Interpolate for numericial value\n",
    "dfC['NrSiblings'] = dfC['NrSiblings'].fillna(dfC['NrSiblings'].mode()[0])\n",
    "\n",
    "# Use Mode for categoricial columns\n",
    "dfC['EthnicGroup'] = dfC['EthnicGroup'].fillna(dfC['EthnicGroup'].mode()[0])\n",
    "dfC['WklyStudyHours'] = dfC['WklyStudyHours'].fillna(dfC['WklyStudyHours'].mode()[0])\n",
    "dfC['ParentEduc'] = df['ParentEduc'].fillna(df['ParentEduc'].mode()[0])\n",
    "dfC['ParentMaritalStatus'] = dfC['ParentMaritalStatus'].fillna(dfC['ParentMaritalStatus'].mode()[0])\n",
    "# Use Mode for binary columns\n",
    "dfC['IsFirstChild'] = dfC['IsFirstChild'].fillna(dfC['IsFirstChild'].mode()[0])\n",
    "dfC['PracticeSport'] = dfC['PracticeSport'].fillna(dfC['PracticeSport'].mode()[0])\n",
    "dfC['TestPrep'] = dfC['TestPrep'].fillna(dfC['TestPrep'].mode()[0])\n",
    "dfC['School_Bus'] = dfC['School_Bus'].fillna(dfC['School_Bus'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfP = dfC.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfP[\"Grade\"] = (dfP[\"WritingScore\"] + dfP[\"ReadingScore\"] + dfP[\"MathScore\"])/3\n",
    "dfP.drop(columns=[\"WritingScore\", \"ReadingScore\", \"MathScore\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode grade into binary variable\n",
    "dfP[\"Grade\"] = (dfP[\"Grade\"] > dfP[\"Grade\"].quantile(0.75)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and four subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Iterate over the columns and create the distribution plots\n",
    "columns = ['Gender', 'EthnicGroup', 'ParentEduc', 'LunchType']\n",
    "for i, col in enumerate(columns):\n",
    "    ax = axs[i//2, i%2]\n",
    "    dfP[col].value_counts().plot(kind='bar', ax=ax)\n",
    "    ax.set_title(f\"Distribution of {col}\")\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the merged graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways: <br>\n",
    "(1) Data set is balanced regarding gender <br>\n",
    "(2) Data set is unbalanced regarding ethnicity. More than one third of the students stem from ethnicity group C while only about 10% stem from ethnicity group A <br>\n",
    "(3) Data set is unbalanced regarding parent education. More than 30% of the students have parents that went to some college while only about 7% of students come from parents with a Master's degree. (Assumption only highest degree is counted) <br>\n",
    "(4) Data set is unbalanced regarding lunch type. About two third of the students have standard lunches while only one third of students benefit from free/reduced lunches (Context: Low-income children are eligible to receive reduced-price or free meals at school)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "fig, axs = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "# Create the bar plot\n",
    "bar_plot = sns.countplot(data=dfP, x='Grade', ax=axs)\n",
    "axs.set_title('Count of Each Grade')\n",
    "\n",
    "# Annotate the count on top of every bar\n",
    "for p in bar_plot.patches:\n",
    "    bar_plot.annotate(f'{p.get_height()}', \n",
    "                      (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                      ha='center', \n",
    "                      va='center', \n",
    "                      xytext=(0, 5), \n",
    "                      textcoords='offset points')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways: <br>\n",
    "As per construction, one fourth of the studenst have good grades (Grade == 1) while three fourth of the class do not have good grades (Grade == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for students that achieved Grade==1\n",
    "grade_1_data = dfP[dfP['Grade'] == 1]\n",
    "\n",
    "# List of categorical variables\n",
    "cat_vars = ['Gender', 'EthnicGroup', 'ParentEduc', 'TestPrep', 'LunchType', 'ParentMaritalStatus', \n",
    "            'PracticeSport', 'IsFirstChild', 'NrSiblings', 'School_Bus', 'WklyStudyHours']\n",
    "\n",
    "# Melt the DataFrame to have two columns: one for variable names and one for values\n",
    "melted_data = grade_1_data[cat_vars].melt()\n",
    "\n",
    "# Create a FacetGrid\n",
    "g = sns.FacetGrid(data=melted_data, col_wrap=3, col='variable', sharex=False, sharey=False, height=4)\n",
    "g = g.map(sns.countplot, 'value', palette='Set2')\n",
    "\n",
    "# Set axis labels, titles, and x-axis tick labels orientation\n",
    "g.set_axis_labels('Count', 'Category')\n",
    "g.set_titles('{col_name}')\n",
    "g.set_xticklabels(rotation=90)\n",
    "\n",
    "# Annotate the count on top of every bar\n",
    "for ax in g.axes.flat:\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', \n",
    "                    va='center', \n",
    "                    xytext=(0, 5), \n",
    "                    textcoords='offset points')\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot\n",
    "sns.pairplot(data=dfP, hue='Grade', diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = stats.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "# Create a DataFrame to hold the Cramer's V values\n",
    "correlation_matrix = pd.DataFrame(index=dfP.columns, columns=dfP.columns)\n",
    "\n",
    "# Fill the DataFrame with Cramer's V values\n",
    "for i in dfP.columns:\n",
    "    for j in dfP.columns:\n",
    "        correlation_matrix.loc[i, j] = cramers_v(dfP[i], dfP[j])\n",
    "\n",
    "# Convert to numeric\n",
    "correlation_matrix = correlation_matrix.apply(pd.to_numeric)\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(correlation_matrix, annot=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairexplain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
